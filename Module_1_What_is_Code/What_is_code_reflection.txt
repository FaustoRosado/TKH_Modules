Fausto Rosado
Module 1 - TKH Fellowship Vestibule



Q1.
	According to Paul Ford, whenever the computer, via keyboard input, receives the letter 'a' from the user, sends a code to the computer that it interprets and activates steps that direct it to produce an 'a' on the screen. It takes the input signal and scans its memory for what the representation is, as part of its font library, the lines and curves that make up the letter. The rendition of the letter, in position and space on the pixels of the screen, then fills the corresponding pixels that are on the screen. The author likens this to a series of steps, with the input triggering a switch, with logic gates that determine what the user distinctly sees as lowercase 'a' on the screen. It's an exact sequence that happens every time the user types a letter in the keyboard (inputs) and follows a sequence akin to a circuit. 



Q2.
	Computers use input and output to create experiences. When the user provides input, whether a letter typed in the keyboard or a mouse click on a webpages, it enters the computer as code where a program , set of instructions or a language, transforms the input in a binary or lower level language the computer reduces to a set of instructions that the computer carries out until bits of output like a letter on a display or button pressed on a webpage, the sum total is the user experience. It is in this way that the computer continually expects user input, bits of code, that is interpreted by a language, or set of instructions in computer programs, that is reduced to binary and actuates switches that lead user output. In the broader sense the user codes when typing in the keyboard or checks a box in a form. A programmer or coder would use a language to save a set of instructions saved in a file that executes when software carries out those instructions. The computer takes user inputs, or bits of code, say a simple print statement in python, separating individual characters and sequencing in groupings or bits that are wrapped in repeatable bits that further compiled into binaries that the computer can execute. It is this interplay between inputs and outputs via user code and software that runs the code, compiled to binary, is how computers create experiences.



Q3.
	The idea that software developers sell "infinitely reproducible nothings" is mentioned by the author when makers of hardware included subscription based software that runs on the hardware that companies sell. Its the idea that users pay recognized software like Microsoft Word for word-processing and work productivity on the hardware. As open source platforms like Linux and other free software, bundled or not, developers take the user inputs and create the software that meets the needs of the market and make us more productive. These software programs may start out as free but are downloaded more and more by users. Developers build the systems that power the things that run the world. The software is reproducible since present day developer control the machines using libraries developed by others before them. Very little software starts from scratch anymore. 



Q4.
	The idea that code becomes software is inherently a task in problem solving. Programmers typically write code in files that contain language typed in a computer that is executed and compiled and executed to run a set of instructions the computer carries out internally. The code is broken down in the compiler to individual bits or characters, then grouped into further repeatable code, on each character of the initial user code, stored in memory, in repetitive bits, is how code is reduced to binary for computer to execute. Code, the kind that developers write in lines to be saved in files, becomes software when it references things like objects, strings, or other data types, in a sequence to solve a problem, namely capturing a routine, summoning and running when the developers needs to in the code is the hallmark of programming languages and is how code becomes software that directs the steps in binary using other software compilers that reduce the code to binary. 



Q5.
	Algorithms are generally software that a defined instruction used to solve a problem or perform a calculation. In CompSci, in a computer language, this typically means that the calculation is wrapped in a function that may be included in a computer language as part of its built in functions or included in libraries. Programming languages, through the use of invoking functions or running the same code of an algorithm on function arguments, include functions that apply the calculations from algorithms. The author mentions that when one says Google Maps has an algorithm, that is to say Google Maps has function calls that run algorithms when the user inputs directions for Google Maps, the software, to execute. Programming languages contain built in functions that represent algorithms the coder can adopt, constrained only by the imagination and application of the developer. 



Q6.
	The DRY principle is an ideal in programming that the developer need not write code that is verbose and repetitive. It applies when creating a functions that represent same code snippet can be invoked later re-using that code or algorithm. It also applies to setting variables and naming things or ideas once and creating logic around doing things once in the code so that another developer may pick up the code and, assuming understanding of the syntax, can follow the code logically and adopt our code to it.



Q7.
	Object-oriented programming refers to the idea that code is easier to understand if we think of objects as encountered in the real world. When developers adapt the code and function names to the data to which it points at, into separate boxes called 'objects.' It is a way of programming that enablers programmers to think like they are working with real-life entities. In this sense, a class is a blue print of what an object's capabilities are, i.e., think of a car class. An object then is an instance of a class, like a Toyota is an object of the class car. All the behaviors of class car, like acceleration, are the methods. Classes and objects in that sense become global variables that programmers can instantiate and invoke built in methods on. 



Q8.
	Data is related to code in that the management of the former is what programmers try to solve. Data is user-generated in emails and spreadsheets. Other times it is generated by the database created for users to login to websites. Data management is the purview of the programmer and purports to be solved by programming. But increasingly it the generation of said data from the utility of the software by users, that persists in software harnessing all this data collection. It's this software generated and user "big data" that directs software development and its coding concomitants, the monetization of data as related to coding and software development. 



Q9.
	A framework is basically a standard way to build and deploy applications on the web or in software. Usually developers will import something like classes, methods and modules that other developer contributions and fixes to it. Most applications today use frameworks that were often created and shared openly. The use of a framework will guide how one programs and prescribes solutions for, say, like Ruby on Rails, model-view-controller applications. It determines the flow of the application. The tradeoff for the developer is the relative ease in getting working front connected with backend, but the framework will dictate flow and solutions will fall under its influence. Every computer language has multiple frameworks that work with that language. The job of the developer is to match a framework to set of problems the application wants to solve. 



Q10.
	Debugging is the activity of finding the problems with code after it executed and something expected does not happen or errors occur. With syntax, it may forgetting a character like a semi-colon or misplaced symbol where there should not be one. There are also logic error, harder to find, since the code may run, but desired output or something unexpected happens. Most programming languages have built in tools that capture errors at runtime, or isolate them for your reference. Programming is recognizing errors of this sort and identifying how the developer's language of choice captures errors. To debug a program, the coder has to isolate the problem: sometimes an error message may occur; another time a program may crash; or something may run infinitely like a loop, eating away at all system resources. The developer then needs to find and isolate the source code that is causing the error and fix it. It is this constant lookout and anticipation of code errors that define a substantial part of what developers do. They test and retest code to control for unexpected errors. Developer will create processes to find errors, remove them, to make the program function as desired or how one set it out to behave. 



Q11.
	The concerns I had of picking up coding too late in my life are allayed when I read this article. First, developers are like present day artists. My daughter has, for instance, very much is a creative person and loves art. She expressed herself in myriad ways. Whether she takes pencil to sketchpad, layer a background using Procreate application on the iPad, or making jewelry using resin in molds. Her expression of her vision through the many forms of art I liken to my interest in furnishing applications that express who I am and the set of problems I seek to solve. We both have fiddled with Raspbian OS and a bit of python libraries to connect the Pi to circuits and create rudimentary robots. Programming in this way is to see inputs and outputs, whether from python code to turn on a led light connected to a breadboard, or displaying something in the terminal when an input, or button is pressed outside the pi. Coding is inherently an art form. The many frameworks and libraries available to cull from to create expressive applications. 
	Second, understanding logic runs across most languages and having dabbled in javascript, ruby and some python, seeing languages as higher level programs that direct or compile to lower level binary that controls the machinery of the computer assists with understanding why one writes any software to begin with. I'm at a point now when the many devices I have used in my life, including a restoration project including an 10 year old iMac turned linux machine, is something I want to write code and programs for. Decoupling software from hardware constraints to run across operating systems and architectures dovetails with my interest in building hardware when younger. I understand the limits placed on the older hardware by industry players like Microsoft. Developers today create on multiple platforms, increasing on the mobile space.
	Third, and most important, I have used libraries and frameworks, including Ruby on Rails and immediately vibe with the author when he says the use of frameworks prescribes application flow and gives a certain look and feel to your application that adherents will recognize. I never forget the joy in getting a rails app set up and running with a few lines of code. Having seen code previously and using it and reading this article from an industry player demystifying the terms, motivates to use other libraries and frameworks, especially the big front end javascript ones like React and Angular, to create applications that I can showcase on Github relatively quickly. Also, seeing Django work a little like Rails for Python, whets my appetite on what I can do with data visualization, a project I withdrew from last year when I was unable to get D3.js to work properly. 
	Understanding that the code and applying logic and algorithms to problems using code will empower to create applications in fields where I have experience in and in endeavors where I have recently ventured out to, like providing IT, or troubleshooting technology products for clients. I will be able to monetize and make an application for my own business as well. Like the author I have been using computer for over 20 years, having seen Microsoft and hardware manufacturers control the market and then Apple create and dominate the mobile space, and have developers use Xcode to have applications run across the many apple ecosystem platforms. This read only enhances for me why coding is not only important to learn for a job, but that developers and coders will continue to transform other fields of the economy uninterrupted.

